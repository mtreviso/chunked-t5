{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9714f006-b7ca-4edf-9f4f-959a95dd102c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n",
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "%env TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3af7b466-24f7-401f-b2e7-1b62190ba133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from utils import merge_input_and_gen_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca10aa32-5b3a-40be-bc13-8386aa8f44e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-24 17:40:09.178007: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "from modeling_ct5 import CT5ForConditionalGeneration\n",
    "\n",
    "dirname = 'ct5-small-en-wiki-pytorch'\n",
    "tokenizer = AutoTokenizer.from_pretrained(dirname)\n",
    "model_ct5 = CT5ForConditionalGeneration.from_pretrained(dirname)\n",
    "model_t5 = T5ForConditionalGeneration.from_pretrained(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5bfce8d-597f-4a31-8061-a2d15adf04f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ct5 = model_ct5.eval()\n",
    "model_t5 = model_t5.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6119f7fd-75b1-457e-8cb0-14d522be9411",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"The <extra_id_0> walks in <extra_id_1> park\",\n",
    "    \"UN Chief says there is no way to <extra_id_0> in Syria\",\n",
    "]\n",
    "input_ids = tokenizer(texts, return_tensors=\"pt\", padding=True).input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9b784f2-330a-4c36-8f5c-dbca9cceab93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtreviso/spectra-t5/env/lib/python3.8/site-packages/functorch/_src/vmap.py:365: UserWarning: There is a performance drop because we have not yet implemented the batching rule for aten::repeat_interleave.Tensor. Please file us an issue on GitHub so that we can prioritize its implementation. (Triggered internally at  /__w/functorch/functorch/functorch/csrc/BatchedFallback.cpp:83.)\n",
      "  batched_outputs = func(*batched_inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    0, 32099,  1061,     0, 32098,     8,     0, 32097,     1],\n",
       "        [    0, 32099,   129,     0, 32098,     1,     0,     0,     0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids = model_ct5.generate(\n",
    "    input_ids, \n",
    "    attention_mask=input_ids != 0,\n",
    "    use_cache=False,\n",
    "    do_sample=True,\n",
    "    top_p=0.95,\n",
    "    top_k=30,\n",
    "    num_beams=1,\n",
    "    eoc_token_id=tokenizer.vocab['</c>'],\n",
    "    max_chunk_size=1,\n",
    ")\n",
    "generated_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "708ef306-4b9e-43c2-99c7-46aeae0c1d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Park walks in the park\n",
      "UN Chief says there is no way to get in Syria\n"
     ]
    }
   ],
   "source": [
    "merged_ids = merge_input_and_gen_ids(input_ids, generated_ids)\n",
    "for i in range(len(merged_ids)):\n",
    "    print(tokenizer.decode(merged_ids[i], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19b043e-62c9-4723-a030-73ed95fe5e44",
   "metadata": {},
   "source": [
    "### Outputing scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3563fb46-28c4-47d9-b188-4683309b9ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The New Zealand Park is  walks in the park\n",
      "UN Chief says there is no way to see anything. References in Syria\n",
      "5\n",
      "(tensor([0, 0, 1]), tensor([0, 0, 1]), tensor([0, 1]), tensor([0, 1]), tensor([0, 1]))\n"
     ]
    }
   ],
   "source": [
    "out = model_ct5.generate(\n",
    "    input_ids, \n",
    "    attention_mask=input_ids != 0,\n",
    "    use_cache=False,\n",
    "    do_sample=True,\n",
    "    top_p=0.95,\n",
    "    top_k=30,\n",
    "    eoc_token_id=tokenizer.vocab['</c>'],\n",
    "    max_chunk_size=5,\n",
    "    output_scores=True,\n",
    "    return_dict_in_generate=True\n",
    ")\n",
    "generated_ids = out['sequences']\n",
    "scores = out['scores']\n",
    "\n",
    "merged_ids = merge_input_and_gen_ids(input_ids, generated_ids)\n",
    "for i in range(len(merged_ids)):\n",
    "    print(tokenizer.decode(merged_ids[i], skip_special_tokens=True))\n",
    "print(len(scores))\n",
    "print(out['inverse_indices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c881b9c5-1336-40a8-9fcf-2ace0f299411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reorder scores according to inverse_indices\n",
    "inverse_idxs = torch.cat(out['inverse_indices'])\n",
    "rev_inverse_idxs = inverse_idxs.argsort()\n",
    "slices = torch.unique(inverse_idxs, return_counts=True)[1].cumsum(dim=-1)\n",
    "scores = torch.cat(scores)[rev_inverse_idxs].tensor_split(slices)[:-1]\n",
    "len(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6444eb91-139a-4e0c-ac05-de9c48e7e377",
   "metadata": {},
   "source": [
    "## Comparing with the original T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96e1f77a-fd4b-4636-ae5a-fc7a7f681bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Ling is A park (. References References External The Reference walks in park\n",
      "UN Chief says there is no way to use. References Damulel History peopleles in Syria\n"
     ]
    }
   ],
   "source": [
    "generated_ids = model_t5.generate(\n",
    "    input_ids, \n",
    "    attention_mask=input_ids != 0,\n",
    "    use_cache=True,\n",
    "    do_sample=True,\n",
    "    top_p=0.95,\n",
    "    top_k=30,\n",
    "    num_beams=1,\n",
    ")\n",
    "merged_ids = merge_input_and_gen_ids(input_ids, generated_ids)\n",
    "for i in range(len(merged_ids)):\n",
    "    print(tokenizer.decode(merged_ids[i], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802a4acf-6499-43d8-9745-a31c9f1a8de4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
